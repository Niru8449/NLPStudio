{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  **Masked Language Modeling with BERT**\n",
        "\n",
        "Explore masked language modeling (MLM) using the BERT model to understand context and predict missing words in sentences.\n",
        "\n",
        "##  Setup and Installation\n",
        "\n",
        "Begin by installing the necessary libraries to manage data processing and modeling."
      ],
      "metadata": {
        "id": "I5iFcukqj02C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS3zor0JJkEk",
        "outputId": "770be7fd-fd42-4e64-9500-ad4478f36bc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Importing Libraries\n",
        "\n",
        "Import essential modules for our tasks."
      ],
      "metadata": {
        "id": "8yPhmjJ3jdGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.special import softmax"
      ],
      "metadata": {
        "id": "l_Hj60F0KSfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Model Setup\n",
        "\n",
        "Load the pre-trained BERT model and tokenizer, specifically designed for masked language modeling."
      ],
      "metadata": {
        "id": "bfK2U28pkAM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bert-base-cased\"\n",
        "\n",
        "# Loading the pre-trained model and tokenizer\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3djcnLf8KT0Q",
        "outputId": "9a28dda4-688d-4b83-b4ef-c6885ad100f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Defining the Mask Token\n",
        "\n",
        "Identify the mask token used by BERT to signify where predictions are needed in the sentence.\n",
        "\n",
        "##  Creating the Input Sentence\n",
        "\n",
        "Craft a sentence with a missing word indicated by the mask token, to test the model's predictive power."
      ],
      "metadata": {
        "id": "gzA6FM8PkDLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the mask token\n",
        "mask = tokenizer.mask_token\n",
        "\n",
        "# Defining the sentence\n",
        "sentence = f\"I want to {mask} pizza for tonight.\"\n",
        "\n",
        "# Tokenizing the sentence\n",
        "tokens = tokenizer.tokenize(sentence)"
      ],
      "metadata": {
        "id": "xJ84BBovKVY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Tokenization and Encoding\n",
        "\n",
        "Tokenize and encode the sentence to format it properly for the model.\n",
        "\n",
        "##  Model Prediction\n",
        "\n",
        "Feed the encoded inputs to the model and extract logits for predictions."
      ],
      "metadata": {
        "id": "vmEsb1l1kLd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding the input sentence and getting model predictions\n",
        "encoded_inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
        "output = model(**encoded_inputs)"
      ],
      "metadata": {
        "id": "NfgQ5Tr3KW3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detaching the logits from the model output and converting to numpy array\n",
        "logits = output.logits.detach().numpy()[0]\n",
        "logits"
      ],
      "metadata": {
        "id": "vwsFgog_O1Dw",
        "outputId": "986c3da7-a046-4762-9701-c18cc90a34af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ -7.3722925,  -7.2488613,  -7.4421444, ...,  -6.311862 ,\n",
              "         -5.936892 ,  -6.425681 ],\n",
              "       [ -7.9311185,  -8.2282095,  -8.032589 , ...,  -6.7387457,\n",
              "         -6.4877234,  -6.9525247],\n",
              "       [-12.050008 , -11.797209 , -12.577608 , ...,  -8.451776 ,\n",
              "         -6.7310185,  -8.258566 ],\n",
              "       ...,\n",
              "       [-10.22041  , -10.4314785,  -9.999257 , ...,  -7.9569917,\n",
              "         -6.7193975,  -9.361793 ],\n",
              "       [-12.447125 , -12.536707 , -12.561406 , ...,  -9.908555 ,\n",
              "         -9.421911 , -11.176952 ],\n",
              "       [-14.365711 , -14.522715 , -15.001671 , ..., -11.971546 ,\n",
              "        -11.65692  , -13.449785 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits.shape"
      ],
      "metadata": {
        "id": "qoFKMq-oVxXy",
        "outputId": "6c5f7b87-256e-4021-e306-5c3bfa21e2a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 28996)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##  Analyzing Predictions\n",
        "\n",
        "Retrieve logits for the masked token and calculate confidence scores for possible replacements."
      ],
      "metadata": {
        "id": "Tw2xAZHtkTbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting the logits for the masked token and calculating the confidence scores\n",
        "masked_logits = logits[tokens.index(mask) + 1]\n",
        "confidence_scores = softmax(masked_logits)"
      ],
      "metadata": {
        "id": "u60j3jorKYN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masked_logits"
      ],
      "metadata": {
        "id": "u8SzngKXWWK9",
        "outputId": "4449fc84-e9c5-4845-96be-98b546f61e9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-6.714628 , -6.379109 , -6.1184893, ..., -5.651309 , -3.6572778,\n",
              "       -4.9947314], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_logits.shape"
      ],
      "metadata": {
        "id": "0DfuTFHlWWWE",
        "outputId": "49d55491-3c8b-4607-af99-6f3025abfbcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28996,)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confidence_scores"
      ],
      "metadata": {
        "id": "tMNy9n_GWjaD",
        "outputId": "295efa0a-616f-4f45-d3fb-ae03aff316a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.9159888e-10, 4.0784978e-10, 5.2928079e-10, ..., 8.4446000e-10,\n",
              "       6.2026344e-09, 1.6282734e-09], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Displaying Top Predictions\n",
        "\n",
        "Cycle through the top 5 predicted tokens, substituting the masked token in the original sentence to show the model's suggestions.\n"
      ],
      "metadata": {
        "id": "I-DUVpDxkVkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterating over the top 5 predicted tokens and printing the sentences with the masked token replaced\n",
        "for i in np.argsort(confidence_scores)[::-1][:5]:\n",
        "    pred_token = tokenizer.decode(i)\n",
        "    score = confidence_scores[i]\n",
        "\n",
        "    # print(pred_token, score)\n",
        "    print(sentence.replace(mask, pred_token))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFBP8-fBKZcv",
        "outputId": "20a4d5f0-28eb-44a1-b759-92a4490c8d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I want to have pizza for tonight.\n",
            "I want to get pizza for tonight.\n",
            "I want to eat pizza for tonight.\n",
            "I want to make pizza for tonight.\n",
            "I want to order pizza for tonight.\n"
          ]
        }
      ]
    }
  ]
}